{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fine-tune Mistral on SVG (LoRA / Q-LoRA)\n",
        "\n",
        "Minimal, production-style notebook that calls into the modular code in `src/`.\n",
        "Edit `configs/default.yaml` or set environment variables for paths and hyperparameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Optional: install dependencies for local runs (uncomment if needed)\n",
        "# !pip install -r ../requirements.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Make project root importable so we can `import src.*`\n",
        "import sys, os\n",
        "from pathlib import Path\n",
        "PROJECT_ROOT = Path('..').resolve()\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.append(str(PROJECT_ROOT))\n",
        "print('Project root:', PROJECT_ROOT)\n",
        "print('Contents:', list(PROJECT_ROOT.iterdir()))\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Preview config\n",
        "import yaml\n",
        "cfg_path = PROJECT_ROOT / 'configs' / 'default.yaml'\n",
        "with open(cfg_path, 'r', encoding='utf-8') as f:\n",
        "    cfg = yaml.safe_load(f)\n",
        "cfg\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dataset\n",
        "- Put your dataset at `../data/svg_train.jsonl` **or** set `SVG_DATA_PATH` to the file path.\n",
        "- The dataset must have a `text` column.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Train (LoRA / optional Q-LoRA)\n",
        "from src.train import train as run_train\n",
        "run_train(str(cfg_path))\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Quick inference\n",
        "from src.inference import generate\n",
        "out = generate(\n",
        "    prompt=\"Hello, this is a quick test of the fine-tuned Mistral model.\",\n",
        "    base_model=cfg['model'].get('base_model', 'mistralai/Mistral-7B-v0.1'),\n",
        "    adapter_dir=cfg['training'].get('output_dir', 'mistral-svg-lora'),\n",
        "    max_new_tokens=128,\n",
        ")\n",
        "print(out)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tips\n",
        "- To change hyperparameters, edit `../configs/default.yaml`.\n",
        "- If you run out of memory, reduce `batch_size` or set `load_4bit: true`.\n",
        "- To log to W&B, set `report_to: ['wandb']` and `WANDB_PROJECT` in your environment.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}